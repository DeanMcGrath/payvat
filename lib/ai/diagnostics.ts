/**
 * OpenAI API Diagnostics Service
 * Comprehensive testing and validation of OpenAI API integration
 */

import { openai, AI_CONFIG, isAIEnabled } from './openai'

export interface OpenAIDiagnosticResult {
  test: string
  success: boolean
  message: string
  details?: any
  responseTime?: number
  error?: string
}

export interface ComprehensiveDiagnostics {
  overall: {
    success: boolean
    summary: string
    timestamp: Date
  }
  tests: OpenAIDiagnosticResult[]
  recommendations: string[]
}

/**
 * Run comprehensive OpenAI API diagnostics
 */
export async function runOpenAIDiagnostics(): Promise<ComprehensiveDiagnostics> {
  const startTime = Date.now()
  console.log('üîç STARTING COMPREHENSIVE OPENAI API DIAGNOSTICS')
  console.log('=' .repeat(80))

  const tests: OpenAIDiagnosticResult[] = []
  let overallSuccess = true
  const recommendations: string[] = []

  // Test 1: API Key Validity
  console.log('1Ô∏è‚É£ Testing API Key Validity...')
  const keyTest = await testAPIKeyValidity()
  tests.push(keyTest)
  if (!keyTest.success) {
    overallSuccess = false
    recommendations.push('Verify OPENAI_API_KEY is set correctly in environment variables')
  }

  // Test 2: Basic Chat Completion
  console.log('2Ô∏è‚É£ Testing Basic Chat Completion...')
  const chatTest = await testBasicChatCompletion()
  tests.push(chatTest)
  if (!chatTest.success) {
    overallSuccess = false
    recommendations.push('Check API key permissions and quota limits')
  }

  // Test 3: Vision Model Access
  console.log('3Ô∏è‚É£ Testing Vision Model Access...')
  const visionTest = await testVisionModelAccess()
  tests.push(visionTest)
  if (!visionTest.success) {
    overallSuccess = false
    recommendations.push('Ensure API key has access to GPT-4 Vision models')
  }

  // Test 4: Image Analysis Capability
  console.log('4Ô∏è‚É£ Testing Image Analysis Capability...')
  const imageTest = await testImageAnalysisCapability()
  tests.push(imageTest)
  if (!imageTest.success) {
    overallSuccess = false
    recommendations.push('Check image format and size limits for Vision API')
  }

  // Test 5: API Quota and Rate Limits
  console.log('5Ô∏è‚É£ Testing API Quota and Rate Limits...')
  const quotaTest = await testAPIQuotaAndLimits()
  tests.push(quotaTest)
  if (!quotaTest.success) {
    overallSuccess = false
    recommendations.push('Check API usage limits and billing status')
  }

  const totalTime = Date.now() - startTime
  const summary = overallSuccess 
    ? `All OpenAI API tests passed (${totalTime}ms)` 
    : `${tests.filter(t => !t.success).length} of ${tests.length} tests failed (${totalTime}ms)`

  console.log('=' .repeat(80))
  console.log(`üéØ DIAGNOSTICS COMPLETE: ${summary}`)
  console.log('=' .repeat(80))

  return {
    overall: {
      success: overallSuccess,
      summary,
      timestamp: new Date()
    },
    tests,
    recommendations
  }
}

/**
 * Test 1: API Key Validity
 */
async function testAPIKeyValidity(): Promise<OpenAIDiagnosticResult> {
  const startTime = Date.now()
  
  try {
    console.log('   Checking environment configuration...')
    
    if (!isAIEnabled()) {
      return {
        test: 'API Key Validity',
        success: false,
        message: 'OpenAI API key not configured or invalid',
        error: 'OPENAI_API_KEY environment variable not set or is placeholder value',
        responseTime: Date.now() - startTime
      }
    }

    console.log('   API key present in environment ‚úÖ')
    
    return {
      test: 'API Key Validity',
      success: true,
      message: 'API key is configured in environment',
      responseTime: Date.now() - startTime
    }

  } catch (error) {
    return {
      test: 'API Key Validity',
      success: false,
      message: 'Failed to validate API key configuration',
      error: error instanceof Error ? error.message : 'Unknown error',
      responseTime: Date.now() - startTime
    }
  }
}

/**
 * Test 2: Basic Chat Completion
 */
async function testBasicChatCompletion(): Promise<OpenAIDiagnosticResult> {
  const startTime = Date.now()
  
  try {
    console.log('   Making simple chat completion request...')
    
    const response = await openai.chat.completions.create({
      model: AI_CONFIG.models.chat,
      messages: [
        {
          role: "user",
          content: "Hello! Please respond with exactly: 'OpenAI API test successful'"
        }
      ],
      max_tokens: 50,
      temperature: 0
    })

    const result = response.choices[0]?.message?.content?.trim()
    console.log(`   Response: "${result}"`)
    
    if (!result) {
      throw new Error('No response content received')
    }

    const isCorrectResponse = result.includes('OpenAI API test successful')
    
    return {
      test: 'Basic Chat Completion',
      success: isCorrectResponse,
      message: isCorrectResponse 
        ? 'Basic chat completion working correctly'
        : 'Chat completion responded but with unexpected content',
      details: {
        expectedResponse: 'OpenAI API test successful',
        actualResponse: result,
        model: AI_CONFIG.models.chat,
        tokensUsed: response.usage
      },
      responseTime: Date.now() - startTime
    }

  } catch (error) {
    console.log(`   Error: ${error instanceof Error ? error.message : 'Unknown error'}`)
    
    return {
      test: 'Basic Chat Completion',
      success: false,
      message: 'Failed to complete basic chat request',
      error: error instanceof Error ? error.message : 'Unknown error',
      responseTime: Date.now() - startTime
    }
  }
}

/**
 * Test 3: Vision Model Access
 */
async function testVisionModelAccess(): Promise<OpenAIDiagnosticResult> {
  const startTime = Date.now()
  
  try {
    console.log('   Testing vision model accessibility...')
    
    // Create a simple test image (1x1 pixel red PNG in base64)
    const testImageBase64 = 'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg=='
    
    const response = await openai.chat.completions.create({
      model: AI_CONFIG.models.vision,
      messages: [
        {
          role: "user",
          content: [
            {
              type: "text",
              text: "This is a test. Please respond with exactly: 'Vision API test successful'"
            },
            {
              type: "image_url",
              image_url: {
                url: `data:image/png;base64,${testImageBase64}`,
                detail: "low"
              }
            }
          ]
        }
      ],
      max_tokens: 50,
      temperature: 0
    })

    const result = response.choices[0]?.message?.content?.trim()
    console.log(`   Response: "${result}"`)
    
    if (!result) {
      throw new Error('No response content received from vision model')
    }

    const isCorrectResponse = result.includes('Vision API test successful')
    
    return {
      test: 'Vision Model Access',
      success: isCorrectResponse,
      message: isCorrectResponse 
        ? 'Vision API is accessible and responding correctly'
        : 'Vision API responded but with unexpected content',
      details: {
        expectedResponse: 'Vision API test successful',
        actualResponse: result,
        model: AI_CONFIG.models.vision,
        tokensUsed: response.usage
      },
      responseTime: Date.now() - startTime
    }

  } catch (error) {
    console.log(`   Error: ${error instanceof Error ? error.message : 'Unknown error'}`)
    
    return {
      test: 'Vision Model Access',
      success: false,
      message: 'Failed to access vision model',
      error: error instanceof Error ? error.message : 'Unknown error',
      responseTime: Date.now() - startTime
    }
  }
}

/**
 * Test 4: Image Analysis Capability
 */
async function testImageAnalysisCapability(): Promise<OpenAIDiagnosticResult> {
  const startTime = Date.now()
  
  try {
    console.log('   Testing image content analysis...')
    
    // Create a simple test image with text (base64 encoded image with "TEST 123.45" text)
    // This is a very basic test - in real implementation you'd have a proper test image
    const testImageBase64 = 'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg=='
    
    const response = await openai.chat.completions.create({
      model: AI_CONFIG.models.vision,
      messages: [
        {
          role: "user",
          content: [
            {
              type: "text",
              text: "Analyze this image and describe what you see. If you can read any text or numbers, please include them in your response."
            },
            {
              type: "image_url",
              image_url: {
                url: `data:image/png;base64,${testImageBase64}`,
                detail: "high"
              }
            }
          ]
        }
      ],
      max_tokens: 100,
      temperature: 0.1
    })

    const result = response.choices[0]?.message?.content?.trim()
    console.log(`   Analysis result: "${result}"`)
    
    if (!result) {
      throw new Error('No analysis response received')
    }

    // For this basic test, any response indicates the vision API can process images
    return {
      test: 'Image Analysis Capability',
      success: true,
      message: 'Vision API can analyze image content',
      details: {
        analysisResponse: result,
        model: AI_CONFIG.models.vision,
        tokensUsed: response.usage
      },
      responseTime: Date.now() - startTime
    }

  } catch (error) {
    console.log(`   Error: ${error instanceof Error ? error.message : 'Unknown error'}`)
    
    return {
      test: 'Image Analysis Capability',
      success: false,
      message: 'Failed to analyze image content',
      error: error instanceof Error ? error.message : 'Unknown error',
      responseTime: Date.now() - startTime
    }
  }
}

/**
 * Test 5: API Quota and Rate Limits
 */
async function testAPIQuotaAndLimits(): Promise<OpenAIDiagnosticResult> {
  const startTime = Date.now()
  
  try {
    console.log('   Testing rate limits and quota...')
    
    // Make multiple quick requests to test rate limiting
    const requests = []
    for (let i = 0; i < 3; i++) {
      requests.push(
        openai.chat.completions.create({
          model: AI_CONFIG.models.chat,
          messages: [
            {
              role: "user", 
              content: `Rate limit test ${i + 1}. Respond with just the number: ${i + 1}`
            }
          ],
          max_tokens: 10,
          temperature: 0
        })
      )
    }

    const responses = await Promise.all(requests)
    console.log(`   Completed ${responses.length} concurrent requests`)
    
    // Check if all responses were successful
    const successCount = responses.filter(r => r.choices[0]?.message?.content).length
    
    return {
      test: 'API Quota and Rate Limits',
      success: successCount === requests.length,
      message: successCount === requests.length 
        ? 'API handling multiple requests without rate limiting'
        : `Only ${successCount} of ${requests.length} requests succeeded`,
      details: {
        requestsMade: requests.length,
        successfulResponses: successCount,
        totalTokensUsed: responses.reduce((sum, r) => sum + (r.usage?.total_tokens || 0), 0)
      },
      responseTime: Date.now() - startTime
    }

  } catch (error) {
    console.log(`   Error: ${error instanceof Error ? error.message : 'Unknown error'}`)
    
    // Check if it's a rate limiting error
    const isRateLimit = error instanceof Error && error.message.includes('rate_limit')
    
    return {
      test: 'API Quota and Rate Limits',
      success: false,
      message: isRateLimit 
        ? 'Rate limiting detected - API may be at quota limits'
        : 'Failed to test rate limits',
      error: error instanceof Error ? error.message : 'Unknown error',
      responseTime: Date.now() - startTime
    }
  }
}

/**
 * Quick OpenAI connectivity test
 */
export async function quickConnectivityTest(): Promise<{success: boolean, message: string, error?: string}> {
  try {
    console.log('üîç Quick OpenAI connectivity test...')
    
    if (!isAIEnabled()) {
      return {
        success: false,
        message: 'OpenAI API key not configured',
        error: 'OPENAI_API_KEY environment variable not set'
      }
    }

    const response = await openai.chat.completions.create({
      model: AI_CONFIG.models.chat,
      messages: [{ role: "user", content: "Test" }],
      max_tokens: 5,
      temperature: 0
    })

    const result = response.choices[0]?.message?.content
    
    return {
      success: !!result,
      message: result ? 'OpenAI API connectivity confirmed' : 'API responded but no content received'
    }

  } catch (error) {
    return {
      success: false,
      message: 'OpenAI API connectivity failed',
      error: error instanceof Error ? error.message : 'Unknown error'
    }
  }
}

/**
 * Compare text extraction vs AI vision processing
 */
export async function compareTextExtractionWithAIVision(
  fileData: string,
  mimeType: string,
  fileName: string
): Promise<{
  textExtractionResult: string
  aiVisionResult: string
  comparison: {
    textContains111_36: boolean
    aiContains111_36: boolean
    textContains103_16: boolean
    aiContains103_16: boolean
    lengthComparison: { text: number, ai: number }
  }
  discrepancies: string[]
}> {
  const discrepancies: string[] = []
  
  console.log('üîç FALLBACK TESTING: Comparing text extraction vs AI vision...')
  
  // 1. Try basic text extraction (if PDF)
  let textExtractionResult = 'N/A'
  if (mimeType === 'application/pdf') {
    try {
      const pdfBuffer = Buffer.from(fileData, 'base64')
      const pdfText = pdfBuffer.toString('utf8')
      
      // Look for text patterns that indicate this might be a text-based PDF
      if (pdfText.includes('/Type /Page') || pdfText.includes('stream')) {
        const textMatches = pdfText.match(/BT[^E]*ET/g) || []
        textExtractionResult = textMatches.map(match => 
          match.replace(/[^a-zA-Z0-9\s‚Ç¨.,:%()-]/g, ' ').replace(/\s+/g, ' ').trim()
        ).filter(text => text.length > 5).join('\n')
      }
    } catch (error) {
      textExtractionResult = `ERROR: ${error instanceof Error ? error.message : 'Unknown error'}`
    }
  }
  
  // 2. Get AI vision result
  let aiVisionResult = 'N/A'
  try {
    const response = await openai.chat.completions.create({
      model: AI_CONFIG.models.vision,
      messages: [
        {
          role: "user",
          content: [
            {
              type: "text",
              text: "Please extract ALL visible text from this document. Do not interpret or summarize - just return everything you can see as raw text."
            },
            {
              type: "image_url",
              image_url: {
                url: `data:${mimeType};base64,${fileData}`,
                detail: "high"
              }
            }
          ]
        }
      ],
      max_tokens: 1000,
      temperature: 0
    })
    
    aiVisionResult = response.choices[0]?.message?.content?.trim() || 'No response'
  } catch (error) {
    aiVisionResult = `ERROR: ${error instanceof Error ? error.message : 'Unknown error'}`
  }
  
  // 3. Compare results
  const comparison = {
    textContains111_36: textExtractionResult.includes('111.36'),
    aiContains111_36: aiVisionResult.includes('111.36'),
    textContains103_16: textExtractionResult.includes('103.16'),
    aiContains103_16: aiVisionResult.includes('103.16'),
    lengthComparison: { 
      text: textExtractionResult.length, 
      ai: aiVisionResult.length 
    }
  }
  
  // 4. Identify discrepancies
  if (comparison.textContains111_36 && !comparison.aiContains111_36) {
    discrepancies.push('Text extraction found ‚Ç¨111.36 but AI vision did not')
  }
  if (!comparison.textContains111_36 && comparison.aiContains111_36) {
    discrepancies.push('AI vision found ‚Ç¨111.36 but text extraction did not')
  }
  if (comparison.textContains103_16 && !comparison.aiContains103_16) {
    discrepancies.push('Text extraction found ‚Ç¨103.16 but AI vision did not')
  }
  if (!comparison.textContains103_16 && comparison.aiContains103_16) {
    discrepancies.push('AI vision found ‚Ç¨103.16 but text extraction did not')
  }
  
  // Check for significant length differences
  if (Math.abs(comparison.lengthComparison.text - comparison.lengthComparison.ai) > 500) {
    discrepancies.push(`Significant length difference: text=${comparison.lengthComparison.text}, AI=${comparison.lengthComparison.ai}`)
  }
  
  console.log('üîç COMPARISON RESULTS:')
  console.log(`   Text extraction length: ${comparison.lengthComparison.text}`)
  console.log(`   AI vision length: ${comparison.lengthComparison.ai}`)
  console.log(`   Text contains ‚Ç¨111.36: ${comparison.textContains111_36}`)
  console.log(`   AI contains ‚Ç¨111.36: ${comparison.aiContains111_36}`)
  console.log(`   Text contains ‚Ç¨103.16: ${comparison.textContains103_16}`)
  console.log(`   AI contains ‚Ç¨103.16: ${comparison.aiContains103_16}`)
  console.log(`   Discrepancies found: ${discrepancies.length}`)
  
  return {
    textExtractionResult,
    aiVisionResult,
    comparison,
    discrepancies
  }
}

/**
 * Test document processing with known test case
 */
export async function testDocumentProcessingDiagnostics(
  testImageBase64: string,
  expectedAmount: number = 111.36
): Promise<OpenAIDiagnosticResult> {
  const startTime = Date.now()
  
  try {
    console.log('üß™ TESTING DOCUMENT PROCESSING WITH KNOWN CASE')
    console.log(`   Expected VAT amount: ‚Ç¨${expectedAmount}`)
    console.log(`   Image size: ${Math.round(testImageBase64.length / 1024)}KB (base64)`)
    
    const response = await openai.chat.completions.create({
      model: AI_CONFIG.models.vision,
      messages: [
        {
          role: "user",
          content: [
            {
              type: "text",
              text: `CRITICAL TEST: This document should contain exactly ‚Ç¨${expectedAmount} as the Total Amount VAT.

Analyze this document and extract VAT information. 

SPECIFIC INSTRUCTIONS:
- Look for "Total Amount VAT" field
- Look for VAT breakdown tables
- Return the EXACT amount you see in the document
- Do NOT guess or calculate - only extract what you can clearly see

Please respond with JSON format:
{
  "totalVatAmount": [exact number you see],
  "confidence": [0-1],
  "extractedText": "[relevant text you can read]",
  "reasoning": "[explain what you see and why you chose this amount]"
}`
            },
            {
              type: "image_url",
              image_url: {
                url: `data:application/pdf;base64,${testImageBase64}`,
                detail: "high"
              }
            }
          ]
        }
      ],
      max_tokens: 500,
      temperature: 0.1
    })

    const result = response.choices[0]?.message?.content?.trim()
    console.log('ü§ñ RAW AI RESPONSE FOR DIAGNOSTIC TEST:')
    console.log('=' .repeat(60))
    console.log(result || 'No response')
    console.log('=' .repeat(60))
    
    if (!result) {
      throw new Error('No response from AI for document test')
    }

    // Try to parse the JSON response
    let parsedResult: any = {}
    try {
      const jsonMatch = result.match(/\{[\s\S]*\}/)
      if (jsonMatch) {
        parsedResult = JSON.parse(jsonMatch[0])
      }
    } catch (parseError) {
      console.log('‚ö†Ô∏è Failed to parse JSON, analyzing raw response...')
    }

    const extractedAmount = parsedResult.totalVatAmount || 0
    const isCorrect = Math.abs(extractedAmount - expectedAmount) < 0.01
    
    console.log('üîç DIAGNOSTIC TEST RESULTS:')
    console.log(`   Expected: ‚Ç¨${expectedAmount}`)
    console.log(`   Extracted: ‚Ç¨${extractedAmount}`)
    console.log(`   Correct: ${isCorrect}`)
    console.log(`   AI Confidence: ${parsedResult.confidence || 'unknown'}`)
    console.log(`   AI Reasoning: ${parsedResult.reasoning || 'not provided'}`)
    
    return {
      test: 'Document Processing Diagnostic',
      success: isCorrect,
      message: isCorrect 
        ? `Correctly extracted ‚Ç¨${expectedAmount} from test document`
        : `Extracted ‚Ç¨${extractedAmount} instead of expected ‚Ç¨${expectedAmount}`,
      details: {
        expectedAmount,
        extractedAmount,
        aiConfidence: parsedResult.confidence,
        aiReasoning: parsedResult.reasoning,
        extractedText: parsedResult.extractedText,
        rawResponse: result,
        tokensUsed: response.usage
      },
      responseTime: Date.now() - startTime
    }

  } catch (error) {
    console.log(`   Error: ${error instanceof Error ? error.message : 'Unknown error'}`)
    
    return {
      test: 'Document Processing Diagnostic',
      success: false,
      message: 'Failed to process test document',
      error: error instanceof Error ? error.message : 'Unknown error',
      responseTime: Date.now() - startTime
    }
  }
}